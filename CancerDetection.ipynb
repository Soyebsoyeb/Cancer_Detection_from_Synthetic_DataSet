{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1. Installation and Setup\n\n!pip install -q tensorflow==2.12.0\n!pip install -q scikit-learn pandas numpy matplotlib pillow gradio opencv-python\n!pip install -q \"huggingface_hub>=0.14.1\"\n\n\n# 2. Initialization\n\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# 3. Synthetic Data Generation\n\nimport numpy as np\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\ndef generate_synthetic_medical_images(num_samples=1000, img_size=(224, 224)):\n    \"\"\"Generate synthetic medical images with abnormalities\"\"\"\n    X = np.zeros((num_samples, *img_size, 3))\n    y = np.zeros(num_samples)\n    \n    for i in range(num_samples):\n        # Base tissue texture\n        X[i] = np.random.normal(0.5, 0.1, (*img_size, 3))\n        \n        # Add abnormalities (20% of samples)\n        if i % 5 == 0:\n            y[i] = 1\n            center = (np.random.randint(50, img_size[0]-50), \n                     np.random.randint(50, img_size[1]-50))\n            axes = (np.random.randint(15, 40), np.random.randint(15, 40))\n            angle = np.random.randint(0, 180)\n            color = (0.8, 0.1, 0.1)  # Reddish abnormality\n            cv2.ellipse(X[i], center, axes, angle, 0, 360, color, -1)\n            \n            # Add spiculations\n            for _ in range(np.random.randint(5, 15)):\n                length = np.random.randint(5, 20)\n                angle = np.random.randint(0, 360)\n                end_point = (\n                    int(center[0] + length * np.cos(np.radians(angle))),\n                    int(center[1] + length * np.sin(np.radians(angle)))\n                )\n                cv2.line(X[i], center, end_point, color, 1)\n        \n        # Add realistic noise\n        X[i] = cv2.addWeighted(X[i], 0.9, np.random.normal(0, 0.02, (*img_size, 3)), 0.1, 0)\n        X[i] = np.clip(X[i], 0, 1)\n    \n    return X, y\n\n# Generate and split data\nX, y = generate_synthetic_medical_images()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n\n\n# 4. Improved Model Architecture and Training\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, applications, callbacks, regularizers\n\ndef build_improved_model(input_shape=(224, 224, 3)):\n    \"\"\"Enhanced model with better regularization and capacity\"\"\"\n    inputs = layers.Input(shape=input_shape)\n    \n    # Using MobileNetV3Small for better efficiency\n    base_model = applications.MobileNetV3Small(\n        include_top=False,\n        weights='imagenet',\n        input_tensor=inputs,\n        pooling='avg'\n    )\n    \n    # Freeze base model layers\n    base_model.trainable = False\n    \n    # Enhanced classification head\n    x = base_model.output\n    x = layers.Dense(256, activation='relu', \n                   kernel_regularizer=regularizers.l2(0.01))(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.5)(x)\n    outputs = layers.Dense(1, activation='sigmoid')(x)\n    \n    return models.Model(inputs, outputs)\n\n# Build and compile improved model\nmodel = build_improved_model()\n\n# Learning rate schedule\ninitial_learning_rate = 1e-4\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=100,\n    decay_rate=0.96,\n    staircase=True)\n\n# Custom metric callback that handles serialization\nclass SerializableHistory(callbacks.Callback):\n    def __init__(self):\n        super().__init__()\n        self.history = {}\n    \n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(float(v))\n\n# Create callback instance\nhistory_callback = SerializableHistory()\n\n# Compile the model\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n    loss='binary_crossentropy',\n    metrics=[\n        'accuracy',\n        tf.keras.metrics.AUC(name='auc'),\n        tf.keras.metrics.Precision(name='precision'),\n        tf.keras.metrics.Recall(name='recall')\n    ]\n)\n\n# Callbacks\ncallbacks_list = [\n    callbacks.EarlyStopping(patience=10, monitor='val_auc', mode='max', restore_best_weights=True),\n    callbacks.ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-6),\n    history_callback\n]\n\n# Calculate class weights\nclass_weight = {0: 1., 1: len(y_train[y_train==0]) / len(y_train[y_train==1])}\n\n# Train model\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    epochs=30,\n    batch_size=32,\n    callbacks=callbacks_list,\n    class_weight=class_weight,\n    verbose=1\n)\n\n\n# 5. Image Processing Pipeline\n\nfrom skimage import exposure\n\nclass MedicalImagePreprocessor:\n    def __init__(self, target_size=(224, 224)):\n        self.target_size = target_size\n        self.clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n    \n    def preprocess(self, image):\n        \"\"\"Process any input image to model-compatible format\"\"\"\n        # Convert to numpy array if needed\n        if not isinstance(image, np.ndarray):\n            image = np.array(image)\n        \n        # Handle different image formats\n        if len(image.shape) == 2:  # Grayscale\n            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n        elif image.shape[2] == 4:  # RGBA\n            image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)\n        \n        # Resize to model's expected input size\n        image = cv2.resize(image, self.target_size)\n        \n        # Convert to grayscale for processing\n        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n        \n        # Enhancement pipeline\n        enhanced = exposure.equalize_adapthist(gray)\n        enhanced = self.clahe.apply(np.uint8(enhanced*255))\n        enhanced = cv2.medianBlur(enhanced, 3)\n        \n        # Convert back to 3 channels\n        processed = np.stack([enhanced]*3, axis=-1)\n        \n        return processed\n\npreprocessor = MedicalImagePreprocessor(target_size=(224, 224))\n\n\n# 6. Gradio Interface\n\nimport gradio as gr\n\ndef analyze_medical_scan(image, sensitivity=0.5):\n    try:\n        # Preprocess image\n        processed = preprocessor.preprocess(image)\n        \n        # Prepare for model prediction\n        img_array = np.expand_dims(processed, axis=0) / 255.0\n        \n        # Get prediction and ensure it's serializable\n        pred = float(model.predict(img_array, verbose=0)[0][0])\n        \n        # Generate visualization\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n        ax1.imshow(image)\n        ax1.set_title(\"Original Image\")\n        ax2.imshow(processed[:,:,0], cmap='gray')\n        ax2.set_title(\"Processed View\")\n        plt.tight_layout()\n        \n        # Format results with native Python types\n        risk_level = \"High\" if pred > 0.7 else \"Moderate\" if pred > 0.4 else \"Low\"\n        confidence = min(0.99, max(0.01, pred * 1.2))\n        \n        report = {\n            \"Risk Score\": pred,\n            \"Risk Level\": risk_level,\n            \"Confidence\": confidence,\n            \"Recommendation\": get_recommendation(pred, sensitivity)\n        }\n        \n        return report, fig\n        \n    except Exception as e:\n        return {\"Error\": str(e)}, None\n\ndef get_recommendation(score, sensitivity):\n    threshold = 0.3 + (0.4 * sensitivity)\n    if score > threshold + 0.3:\n        return \"Urgent: Immediate specialist consultation recommended\"\n    elif score > threshold:\n        return \"Concerning: Additional diagnostic tests advised\"\n    elif score > threshold - 0.2:\n        return \"Monitor: Follow-up screening recommended\"\n    else:\n        return \"Normal: Routine screening advised\"\n\n# Create Gradio interface\nwith gr.Blocks(theme=gr.themes.Soft()) as demo:\n    gr.Markdown(\"\"\"\n    # <center>Medical Imaging AI</center>\n    ### <center>Cancer Detection System</center>\n    \"\"\")\n    \n    with gr.Row():\n        with gr.Column():\n            scan_input = gr.Image(label=\"Upload Medical Scan\", type=\"numpy\")\n            sensitivity = gr.Slider(0.1, 1.0, value=0.7, label=\"Detection Sensitivity\")\n            analyze_btn = gr.Button(\"Analyze\", variant=\"primary\")\n            \n        with gr.Column():\n            report_output = gr.JSON(label=\"Diagnostic Report\")\n            visualization = gr.Plot(label=\"Scan Analysis\")\n    \n    with gr.Accordion(\"Model Information\", open=False):\n        gr.Markdown(f\"\"\"\n        - *Model*: MobileNetV3Small\n        - *Validation AUC*: {history_callback.history['val_auc'][-1]:.4f}\n        - *Input Size*: 224Ã—224 pixels\n        - *Processing*: CLAHE + Adaptive Histogram Equalization\n        \"\"\")\n\n    analyze_btn.click(\n        fn=analyze_medical_scan,\n        inputs=[scan_input, sensitivity],\n        outputs=[report_output, visualization]\n    )\n\n# Launch the app\ndemo.launch(share=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T10:49:10.797418Z","iopub.execute_input":"2025-06-21T10:49:10.798194Z","iopub.status.idle":"2025-06-21T10:52:16.352143Z","shell.execute_reply.started":"2025-06-21T10:49:10.798169Z","shell.execute_reply":"2025-06-21T10:52:16.351557Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float_no_top_v2.h5\n4334752/4334752 [==============================] - 0s 0us/step\nEpoch 1/30\n25/25 [==============================] - 11s 264ms/step - loss: 4.5174 - accuracy: 0.6513 - auc: 0.6873 - precision: 0.3169 - recall: 0.6438 - val_loss: 3.9305 - val_accuracy: 0.8000 - val_auc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\nEpoch 2/30\n25/25 [==============================] - 5s 192ms/step - loss: 4.2250 - accuracy: 0.7575 - auc: 0.8727 - precision: 0.4422 - recall: 0.8125 - val_loss: 3.6582 - val_accuracy: 0.8000 - val_auc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\nEpoch 3/30\n25/25 [==============================] - 5s 195ms/step - loss: 3.9582 - accuracy: 0.7825 - auc: 0.9155 - precision: 0.4771 - recall: 0.9125 - val_loss: 3.4056 - val_accuracy: 0.8000 - val_auc: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\nEpoch 4/30\n25/25 [==============================] - 5s 195ms/step - loss: 3.7078 - accuracy: 0.8062 - auc: 0.9575 - precision: 0.5084 - recall: 0.9438 - val_loss: 3.1722 - val_accuracy: 0.8000 - val_auc: 0.6438 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\nEpoch 5/30\n25/25 [==============================] - 6s 227ms/step - loss: 3.4793 - accuracy: 0.8363 - auc: 0.9681 - precision: 0.5520 - recall: 0.9625 - val_loss: 2.9650 - val_accuracy: 0.8000 - val_auc: 0.8969 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 9.6000e-05\nEpoch 6/30\n25/25 [==============================] - 5s 196ms/step - loss: 3.2733 - accuracy: 0.8400 - auc: 0.9729 - precision: 0.5576 - recall: 0.9688 - val_loss: 2.7942 - val_accuracy: 0.8000 - val_auc: 0.8600 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 9.6000e-05\nEpoch 7/30\n25/25 [==============================] - 5s 196ms/step - loss: 3.0838 - accuracy: 0.8500 - auc: 0.9755 - precision: 0.5730 - recall: 0.9812 - val_loss: 2.6186 - val_accuracy: 0.8000 - val_auc: 0.9540 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 9.6000e-05\nEpoch 8/30\n25/25 [==============================] - 5s 205ms/step - loss: 2.9054 - accuracy: 0.8612 - auc: 0.9761 - precision: 0.5946 - recall: 0.9625 - val_loss: 2.4780 - val_accuracy: 0.8000 - val_auc: 0.9595 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 9.6000e-05\nEpoch 9/30\n25/25 [==============================] - 5s 192ms/step - loss: 2.7402 - accuracy: 0.8725 - auc: 0.9767 - precision: 0.6142 - recall: 0.9750 - val_loss: 2.3468 - val_accuracy: 0.8000 - val_auc: 0.9589 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 9.2160e-05\nEpoch 10/30\n25/25 [==============================] - 5s 197ms/step - loss: 2.5933 - accuracy: 0.8600 - auc: 0.9758 - precision: 0.5930 - recall: 0.9563 - val_loss: 2.2216 - val_accuracy: 0.8300 - val_auc: 0.9666 - val_precision: 1.0000 - val_recall: 0.1500 - lr: 9.2160e-05\nEpoch 11/30\n25/25 [==============================] - 5s 204ms/step - loss: 2.4594 - accuracy: 0.8750 - auc: 0.9762 - precision: 0.6230 - recall: 0.9500 - val_loss: 2.0732 - val_accuracy: 0.8000 - val_auc: 0.9758 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 9.2160e-05\nEpoch 12/30\n25/25 [==============================] - 5s 201ms/step - loss: 2.3256 - accuracy: 0.8700 - auc: 0.9776 - precision: 0.6120 - recall: 0.9563 - val_loss: 1.9338 - val_accuracy: 0.8000 - val_auc: 0.9798 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 9.2160e-05\nEpoch 13/30\n25/25 [==============================] - 5s 194ms/step - loss: 2.2064 - accuracy: 0.8913 - auc: 0.9785 - precision: 0.6540 - recall: 0.9688 - val_loss: 1.8145 - val_accuracy: 0.8000 - val_auc: 0.9823 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 8.8474e-05\nEpoch 14/30\n25/25 [==============================] - 5s 197ms/step - loss: 2.0963 - accuracy: 0.8900 - auc: 0.9812 - precision: 0.6552 - recall: 0.9500 - val_loss: 1.7032 - val_accuracy: 0.8000 - val_auc: 0.9877 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 8.8474e-05\nEpoch 15/30\n25/25 [==============================] - 5s 210ms/step - loss: 1.9963 - accuracy: 0.8838 - auc: 0.9805 - precision: 0.6402 - recall: 0.9563 - val_loss: 1.6280 - val_accuracy: 0.8000 - val_auc: 0.9883 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 8.8474e-05\nEpoch 16/30\n25/25 [==============================] - 5s 208ms/step - loss: 1.8969 - accuracy: 0.9038 - auc: 0.9805 - precision: 0.6861 - recall: 0.9563 - val_loss: 1.5710 - val_accuracy: 0.8000 - val_auc: 0.9893 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 8.8474e-05\nEpoch 17/30\n25/25 [==============================] - 5s 195ms/step - loss: 1.8090 - accuracy: 0.8963 - auc: 0.9802 - precision: 0.6711 - recall: 0.9438 - val_loss: 1.4397 - val_accuracy: 0.8000 - val_auc: 0.9878 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 8.4935e-05\nEpoch 18/30\n25/25 [==============================] - 5s 214ms/step - loss: 1.7357 - accuracy: 0.9000 - auc: 0.9743 - precision: 0.6869 - recall: 0.9187 - val_loss: 1.4159 - val_accuracy: 0.8050 - val_auc: 0.9892 - val_precision: 1.0000 - val_recall: 0.0250 - lr: 8.4935e-05\nEpoch 19/30\n25/25 [==============================] - 5s 205ms/step - loss: 1.6677 - accuracy: 0.8925 - auc: 0.9724 - precision: 0.6637 - recall: 0.9375 - val_loss: 1.3049 - val_accuracy: 0.8000 - val_auc: 0.9883 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 8.4935e-05\nEpoch 20/30\n25/25 [==============================] - 5s 211ms/step - loss: 1.5964 - accuracy: 0.9075 - auc: 0.9800 - precision: 0.7009 - recall: 0.9375 - val_loss: 1.2789 - val_accuracy: 0.8300 - val_auc: 0.9897 - val_precision: 1.0000 - val_recall: 0.1500 - lr: 8.4935e-05\nEpoch 21/30\n25/25 [==============================] - 5s 192ms/step - loss: 1.5291 - accuracy: 0.9187 - auc: 0.9804 - precision: 0.7317 - recall: 0.9375 - val_loss: 1.2526 - val_accuracy: 0.9450 - val_auc: 0.9896 - val_precision: 0.9677 - val_recall: 0.7500 - lr: 8.1537e-05\nEpoch 22/30\n25/25 [==============================] - 5s 205ms/step - loss: 1.4601 - accuracy: 0.9275 - auc: 0.9860 - precision: 0.7476 - recall: 0.9625 - val_loss: 1.1137 - val_accuracy: 0.8050 - val_auc: 0.9897 - val_precision: 1.0000 - val_recall: 0.0250 - lr: 8.1537e-05\nEpoch 23/30\n25/25 [==============================] - 5s 192ms/step - loss: 1.4105 - accuracy: 0.9200 - auc: 0.9795 - precision: 0.7376 - recall: 0.9312 - val_loss: 1.3264 - val_accuracy: 0.2550 - val_auc: 0.9892 - val_precision: 0.2116 - val_recall: 1.0000 - lr: 8.1537e-05\nEpoch 24/30\n25/25 [==============================] - 5s 208ms/step - loss: 1.3525 - accuracy: 0.9212 - auc: 0.9797 - precision: 0.7389 - recall: 0.9375 - val_loss: 1.0301 - val_accuracy: 0.8650 - val_auc: 0.9897 - val_precision: 1.0000 - val_recall: 0.3250 - lr: 8.1537e-05\nEpoch 25/30\n25/25 [==============================] - 5s 197ms/step - loss: 1.3065 - accuracy: 0.9137 - auc: 0.9823 - precision: 0.7177 - recall: 0.9375 - val_loss: 1.1755 - val_accuracy: 0.5300 - val_auc: 0.9893 - val_precision: 0.2985 - val_recall: 1.0000 - lr: 7.8276e-05\nEpoch 26/30\n25/25 [==============================] - 5s 207ms/step - loss: 1.2615 - accuracy: 0.9225 - auc: 0.9804 - precision: 0.7426 - recall: 0.9375 - val_loss: 0.9702 - val_accuracy: 0.9500 - val_auc: 0.9895 - val_precision: 0.9688 - val_recall: 0.7750 - lr: 7.8276e-05\nEpoch 27/30\n25/25 [==============================] - 5s 189ms/step - loss: 1.2150 - accuracy: 0.9237 - auc: 0.9825 - precision: 0.7487 - recall: 0.9312 - val_loss: 0.9421 - val_accuracy: 0.9650 - val_auc: 0.9895 - val_precision: 0.9459 - val_recall: 0.8750 - lr: 7.8276e-05\nEpoch 28/30\n25/25 [==============================] - 5s 191ms/step - loss: 1.1752 - accuracy: 0.9250 - auc: 0.9844 - precision: 0.7551 - recall: 0.9250 - val_loss: 0.9279 - val_accuracy: 0.9650 - val_auc: 0.9895 - val_precision: 0.8837 - val_recall: 0.9500 - lr: 7.8276e-05\nEpoch 29/30\n25/25 [==============================] - 5s 192ms/step - loss: 1.1471 - accuracy: 0.9262 - auc: 0.9791 - precision: 0.7644 - recall: 0.9125 - val_loss: 1.0188 - val_accuracy: 0.6350 - val_auc: 0.9897 - val_precision: 0.3540 - val_recall: 1.0000 - lr: 7.5145e-05\nEpoch 30/30\n25/25 [==============================] - 5s 206ms/step - loss: 1.1015 - accuracy: 0.9362 - auc: 0.9854 - precision: 0.7853 - recall: 0.9375 - val_loss: 0.9873 - val_accuracy: 0.6550 - val_auc: 0.9901 - val_precision: 0.3670 - val_recall: 1.0000 - lr: 7.5145e-05\n* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://2a27790ada4470e62b.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://2a27790ada4470e62b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}